{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio,seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data based on the given ratio: TODO\n",
    "    # ***************************************************\n",
    "    indices = np.random.permutation(x.shape[0])\n",
    "    training_ratio = int(np.floor(ratio * x.shape[0]))\n",
    "\n",
    "    x_training = x[indices[0:training_ratio]]\n",
    "    y_training = y[indices[0:training_ratio]]\n",
    "    x_testing = x[indices[training_ratio:]]\n",
    "    y_testing = y[indices[training_ratio:]]\n",
    "    \n",
    "    return x_training, x_testing, y_training, y_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Removing bothering data and centering\n",
    "tX[tX==-999] = 0\n",
    "m = np.mean(tX, axis=0)\n",
    "centered_tX = tX - m\n",
    "\n",
    "centered_tX[centered_tX==0] = float('nan')\n",
    "stdevtrain = np.nanstd(centered_tX, axis=0)\n",
    "centered_tX[centered_tX==float('nan')] = 0\n",
    "standardized_tX = centered_tX / stdevtrain\n",
    "\n",
    "d = len(standardized_tX[0])\n",
    "n = len(standardized_tX)\n",
    "indices_s_deg = []\n",
    "\n",
    "# Creating indices for subsets of degree 2\n",
    "for i in range (d):\n",
    "    for t in range (i,d): \n",
    "        indices_s_deg.append([t, i])\n",
    "indices_s_deg = np.array(indices_s_deg).T\n",
    "\n",
    "degrees = range(3,11)\n",
    "degrees_number = len(degrees) + 1\n",
    "stdX_Ncols = standardized_tX.shape[1]\n",
    "indices_s_Ncols = indices_s_deg.shape[1]\n",
    "number_of_rows = indices_s_Ncols + degrees_number * stdX_Ncols\n",
    "\n",
    "mat = np.zeros((n, number_of_rows))\n",
    "\n",
    "# First degree\n",
    "mat[:, :stdX_Ncols] = standardized_tX\n",
    "\n",
    "# Second degree gotten from indices\n",
    "mat[:,stdX_Ncols:stdX_Ncols + indices_s_Ncols] = standardized_tX[:, indices_s_deg[0]] * standardized_tX[:, indices_s_deg[1]]\n",
    "\n",
    "# Improve 3 to 10 degree\n",
    "for i in degrees:\n",
    "    start_index = indices_s_Ncols + (i - 2) * stdX_Ncols\n",
    "    end_index = start_index + stdX_Ncols\n",
    "    mat[:,start_index:end_index] = standardized_tX**i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#excluded=[]\n",
    "#for i in range (len(mat[0])):\n",
    "#    a=np.corrcoef(y,mat[:,i])\n",
    "#    if abs(a[0,1])<10**-3:\n",
    "#        excluded.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mat=np.delete(mat,excluded,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m2 = np.mean(mat, axis=0)\n",
    "centered_mat = mat - m2\n",
    "centered_mat[mat==0] = 0\n",
    "\n",
    "centered_mat[centered_mat==0] = float('nan')\n",
    "stdev = np.nanstd(centered_mat, axis=0)\n",
    "centered_mat[centered_mat==float('nan')] = 0\n",
    "standardized_mat = centered_mat / stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples = len(standardized_mat)\n",
    "tx = np.c_[np.ones(num_samples), standardized_mat]\n",
    "#y=list(y)\n",
    "#y[y==-1]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss.\n",
    "    \n",
    "    You can calculate the loss using mse or mae.\n",
    "    \"\"\"\n",
    "    e = y - np.dot(tx, w)\n",
    "    mse = np.dot(e.transpose(), e) / (2 * len(tx))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tX, testx, y, testy = split_data(tx, y, 0.8, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np \n",
    "def logistic(a):\n",
    "    return 1.0 / (1 + np.exp(-a))\n",
    "def irls(X, y):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    theta_ = np.inf\n",
    "    eps = 60000\n",
    "    lamda = 5\n",
    "    for aqua in range (11):\n",
    "        grad = np.zeros(X.shape[1])\n",
    "        a = np.dot(X, theta)\n",
    "        #a=math.log10(abs(a))*sign(a)\n",
    "        #print(min(a),max(a))\n",
    "        pi = logistic(a)        \n",
    "        SX = X * (pi - pi*pi).reshape(-1, 1)\n",
    "        XSX = np.dot(X.T, SX)\n",
    "        #+lamda*np.eye((len(X[0])))\n",
    "        for aw in range (len(X)):\n",
    "            grad = grad + (-1 / len(X)) * (y[aw] * X[aw, :] * logistic(-y[aw] * np.dot(X[aw,:], theta)))\n",
    "        \n",
    "        \n",
    "     \n",
    "        theta = theta - eps * np.linalg.solve(XSX, grad)\n",
    "        print(sum(y == np.sign(np.dot(X, theta))) / len(y))\n",
    "       \n",
    "        if aqua % 5 == 0 and aqua != 0:\n",
    "            eps = eps * 0.8\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82505\n",
      "0.826655\n",
      "0.828295\n",
      "0.829095\n",
      "0.831\n",
      "0.831925\n",
      "0.832935\n",
      "0.833575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/.local/lib/python3.5/site-packages/ipykernel/__main__.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834155\n",
      "0.83477\n",
      "0.834845\n"
     ]
    }
   ],
   "source": [
    "theta=irls(tX,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeing memory\n",
      "Freeing the matrix memory again\n"
     ]
    }
   ],
   "source": [
    "print(\"Freeing memory\")\n",
    "del(mat)\n",
    "del(DATA_TRAIN_PATH)\n",
    "del(y)\n",
    "del(tx)\n",
    "del(ids)\n",
    "weights = theta\n",
    "testx = tX_test\n",
    "#testx=np.delete(testx,[14,15,17,18,24,25,27,28],axis=1)\n",
    "testx[testx==-999] = 0\n",
    "#m2=np.mean(testx,axis=0)\n",
    "centered_testx = testx - m\n",
    "centered_testx[testx==-999] = 0\n",
    "#standardized_testx=centered_testx / np.std(centered_testx, axis=0)\n",
    "#centered_testx[centered_testx==0]=float('nan')\n",
    "#stdevtest=np.nanstd(centered_testx,axis=0);\n",
    "#centered_testx[centered_testx==float('nan')]=0\n",
    "standardized_testx = centered_testx / stdevtrain\n",
    "\n",
    "d = len(standardized_testx[0])\n",
    "n = len(standardized_testx)\n",
    "indices_s_deg = []\n",
    "\n",
    "# Creating indices for subsets of degree 2\n",
    "for i in range (d):\n",
    "    for t in range (i,d): \n",
    "        indices_s_deg.append([t, i])\n",
    "indices_s_deg = np.array(indices_s_deg).T\n",
    "\n",
    "degrees = range(3,11)\n",
    "degrees_number = len(degrees) + 1\n",
    "stdX_Ncols = standardized_testx.shape[1]\n",
    "indices_s_Ncols = indices_s_deg.shape[1]\n",
    "number_of_rows = indices_s_Ncols + degrees_number * stdX_Ncols\n",
    "\n",
    "mat = np.zeros((n, number_of_rows))\n",
    "\n",
    "# First degree\n",
    "mat[:, :stdX_Ncols] = standardized_testx\n",
    "\n",
    "# Second degree gotten from indices\n",
    "mat[:,stdX_Ncols:stdX_Ncols + indices_s_Ncols] = standardized_testx[:, indices_s_deg[0]] * standardized_testx[:, indices_s_deg[1]]\n",
    "\n",
    "# Improve 3 to 10 degree\n",
    "for i in degrees:\n",
    "    start_index = indices_s_Ncols + (i - 2) * stdX_Ncols\n",
    "    end_index = start_index + stdX_Ncols\n",
    "    mat[:,start_index:end_index] = standardized_testx**i  \n",
    "        \n",
    "centered_mat = mat - m2\n",
    "centered_mat[mat==0] = 0\n",
    "\n",
    "print(\"Freeing the matrix memory again\")\n",
    "del(mat)\n",
    "\n",
    "#centered_mat[centered_mat==0]=float('nan')\n",
    "#stdev=np.nanstd(centered_mat,axis=0);\n",
    "#centered_mat[centered_mat==float('nan')]=0\n",
    "standardized_testmat = centered_mat / stdev\n",
    "\n",
    "#tao=int(d*(d+1)/2+d)\n",
    "    \n",
    "#for i in range (n):\n",
    "#    for r in range (d):\n",
    "#        for monsoon in range (r,d):\n",
    "#            for t in range (monsoon,d): \n",
    "#                mat[i,tao]=standardized_tX[i,t]*standardized_tX[i,monsoon]*standardized_tX[i,r]\n",
    "#                tao=tao+1\n",
    "#    tao=int(d*(d+1)/2+d)  \n",
    "    \n",
    "num_samples = len(standardized_testmat)\n",
    "final_testx = np.c_[np.ones(num_samples), standardized_testmat]\n",
    "tX_test = final_testx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'deneme8.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = -predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New time for everything: 180.27915120124817 seconds.\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print(\"New time for everything:\", end - start, \"seconds.\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
