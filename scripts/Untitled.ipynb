{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio,seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data based on the given ratio: TODO\n",
    "    # ***************************************************\n",
    "    indices = np.random.permutation(x.shape[0])\n",
    "    training_ratio = int(np.floor(ratio * x.shape[0]))\n",
    "\n",
    "    x_training = x[indices[0:training_ratio]]\n",
    "    y_training = y[indices[0:training_ratio]]\n",
    "    x_testing = x[indices[training_ratio:]]\n",
    "    y_testing = y[indices[training_ratio:]]\n",
    "    \n",
    "    return x_training, x_testing, y_training, y_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating indices...\n",
      "Computing first degree...\n",
      "Computing second degree with combinations...\n",
      "Computing from degree 3 to 10 without combinations...\n",
      "Computing third degree with some combinations...\n"
     ]
    }
   ],
   "source": [
    "# Removing bothering data and centering\n",
    "tX[tX==-999] = 0\n",
    "m = np.mean(tX, axis=0)\n",
    "centered_tX = tX - m\n",
    "\n",
    "centered_tX[centered_tX==0] = float('nan')\n",
    "stdevtrain = np.nanstd(centered_tX, axis=0)\n",
    "centered_tX[centered_tX==float('nan')] = 0\n",
    "standardized_tX = centered_tX / stdevtrain\n",
    "\n",
    "d = len(standardized_tX[0])\n",
    "n = len(standardized_tX)\n",
    "\n",
    "indices_s_deg = []\n",
    "indices_t_deg = []\n",
    "\n",
    "print(\"Creating indices...\")\n",
    "# Creating indices for subsets of degree 2\n",
    "for i in range (d):\n",
    "    for t in range (i,d):\n",
    "        indices_s_deg.append([t, i])\n",
    "indices_s_deg = np.array(indices_s_deg).T\n",
    "\n",
    "# Creating indices for subsets of degree 3\n",
    "max_t_degree = 15\n",
    "for i in range (max_t_degree):\n",
    "    for t in range (i,max_t_degree):\n",
    "        for j in range(t,max_t_degree):\n",
    "            if not (i == t and i == j):\n",
    "                indices_t_deg.append([j, t, i])\n",
    "indices_t_deg = np.array(indices_t_deg).T\n",
    "\n",
    "degrees = range(3,11)\n",
    "degrees_number = len(degrees) + 1\n",
    "stdX_Ncols = standardized_tX.shape[1]\n",
    "indices_s_Ncols = indices_s_deg.shape[1]\n",
    "indices_t_Ncols = indices_t_deg.shape[1]\n",
    "\n",
    "number_of_rows = indices_s_Ncols + degrees_number * stdX_Ncols + indices_t_Ncols\n",
    "\n",
    "mat = np.zeros((n, number_of_rows))\n",
    "\n",
    "print(\"Computing first degree...\")\n",
    "# First degree\n",
    "mat[:, :stdX_Ncols] = standardized_tX\n",
    "\n",
    "print(\"Computing second degree with combinations...\")\n",
    "# Second degree gotten from indices\n",
    "mat[:,stdX_Ncols:stdX_Ncols + indices_s_Ncols] = standardized_tX[:, indices_s_deg[0]] * standardized_tX[:, indices_s_deg[1]]\n",
    "\n",
    "print(\"Computing from degree 3 to 10 without combinations...\")\n",
    "# Improve 3 to 10 degree\n",
    "for i in degrees:\n",
    "    start_index = indices_s_Ncols + (i - 2) * stdX_Ncols\n",
    "    end_index = start_index + stdX_Ncols\n",
    "    mat[:,start_index:end_index] = standardized_tX**i\n",
    "    \n",
    "print(\"Computing third degree with some combinations...\")\n",
    "# Third degree gotten from indices\n",
    "mat[:, number_of_rows - indices_t_Ncols: number_of_rows] = standardized_tX[:, indices_t_deg[0]] * standardized_tX[:, indices_t_deg[1]] * standardized_tX[:, indices_t_deg[2]]\n",
    "\n",
    "\n",
    "m2 = np.mean(mat, axis=0)\n",
    "centered_mat = mat - m2\n",
    "centered_mat[mat==0] = 0\n",
    "\n",
    "centered_mat[centered_mat==0] = float('nan')\n",
    "stdev = np.nanstd(centered_mat, axis=0)\n",
    "centered_mat[centered_mat==float('nan')] = 0\n",
    "standardized_mat = centered_mat / stdev\n",
    "\n",
    "num_samples = len(standardized_mat)\n",
    "tx = np.c_[np.ones(num_samples), standardized_mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss.\n",
    "    \n",
    "    You can calculate the loss using mse or mae.\n",
    "    \"\"\"\n",
    "    e = y - np.dot(tx, w)\n",
    "    mse = np.dot(e.transpose(), e) / (2 * len(tx))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np \n",
    "def logistic(a):\n",
    "    return 1.0 / (1 + np.exp(-a))\n",
    "def irls(X, y):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    theta_ = np.inf\n",
    "    eps=50000\n",
    "    for aqua in range (20):\n",
    "        grad=np.zeros(X.shape[1])\n",
    "        a = np.dot(X, theta)\n",
    "        pi = logistic(a)        \n",
    "        SX = X * (pi - pi*pi).reshape(-1,1)\n",
    "        XSX = np.dot(X.T,SX)\n",
    "        \n",
    "        for aw in range (len(X)):\n",
    "            grad = grad + (-1 / len(X)) * (y[aw] * X[aw,:] * logistic(-y[aw] * np.dot(X[aw,:],theta)))\n",
    "     \n",
    "        theta = theta - eps * np.linalg.solve(XSX, grad)\n",
    "        print(sum(y==np.sign(np.dot(X, theta))) / len(y))\n",
    "       \n",
    "        if aqua % 5==0 and aqua ! =0:\n",
    "            eps = eps * 0.5\n",
    "    return theta\n",
    "\n",
    "def reg_irls(X, y):\n",
    "    theta = np.zeros(X.shape[1])\n",
    "    theta_ = np.inf\n",
    "    eps = 100000\n",
    "    lamda = 10**-8\n",
    "    for aqua in range (15):\n",
    "        grad = np.zeros(X.shape[1])\n",
    "        a = np.dot(X, theta)\n",
    "        pi = logistic(a)        \n",
    "        SX = X * (pi - pi*pi).reshape(-1,1)\n",
    "        XSX = np.dot(X.T,SX) + lamda * np.eye((len(X[0])))\n",
    "        for aw in range (len(X)):\n",
    "            grad = grad + (-1 / len(X)) * (y[aw] * X[aw,:] * logistic(-y[aw] * np.dot(X[aw,:],theta)))\n",
    "        \n",
    "        theta = theta - eps * np.linalg.solve(XSX, grad) - eps * lamda * theta\n",
    "        print(sum(y==np.sign(np.dot(X, theta))) / len(y))\n",
    "       \n",
    "        if aqua % 5==0 and aqua != 0:\n",
    "            eps = eps * 0.5\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Freeing memory\")\n",
    "del(centered_mat, centered_tX, standardized_mat, standardized_tX, stdX_Ncols)\n",
    "del(indices_s_deg, indices_s_Ncols, indices_t_deg, indices_t_Ncols)\n",
    "del(mat, DATA_TRAIN_PATH, ids, stdev, testx, testy)\n",
    "\n",
    "lens = [(x,len(x)) for x in set(dir()) - set(dir(__builtins__))]\n",
    "testout = sorted(lens, key=lambda l: l[1])\n",
    "print(testout[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    \"\"\"calculate the least squares solution.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least squares: TODO\n",
    "    # returns mse, and optimal weights\n",
    "    xtx=np.dot(tx.transpose(),tx)\n",
    "    xy=np.dot(tx.transpose(),y)\n",
    "    w=np.dot(np.linalg.inv(xtx),xy)\n",
    "    #e=y-np.dot(tx,w)\n",
    "    #mse=np.dot(e.transpose(),e)/(2*len(tx))\n",
    "    return w\n",
    "    # ***************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lamb):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    xtx=np.dot(tx.transpose(),tx)\n",
    "    l_inside=2*lamb*len(tx)*np.eye(tx.shape[1])\n",
    "    ins=xtx+l_inside\n",
    "    xy=np.dot(tx.transpose(),y)\n",
    "    \n",
    "    w=np.dot(np.linalg.inv(ins),xy)\n",
    "    e=y-np.dot(tx,w)\n",
    "    mse=np.dot(e.transpose(),e)/(2*len(tx))\n",
    "    \n",
    "    return w\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Compute the gradient.\"\"\"\n",
    "    # ***************************************************\n",
    "    e=y-np.dot(tx,w)\n",
    "    return (-1/len(tx))*np.dot(tx.transpose(),e)\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, gamma, max_iters):\n",
    "    \"\"\"Gradient descent algorithm.\"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    initial_w=np.zeros(tx.shape[1])\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        grad=compute_gradient(y,tx,w)\n",
    "        loss=compute_loss(y,tx,w)\n",
    "        # ***************************************************\n",
    "        gamma=gamma/1.005\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        w=w-gamma*grad\n",
    "        # ***************************************************\n",
    "        \n",
    "        # store w and loss\n",
    "        ws.append(np.copy(w))\n",
    "        losses.append(loss)\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "              bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_iters = 500\n",
    "gamma = 0.025\n",
    "gradient_losses, gradient_w = least_squares_GD(y1, x1, gamma, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "least_squares_w=least_squares(y1,x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lamb=0.00075\n",
    "ridge_w=ridge_regression(y1, x1, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[i for i in range (200000,250000)]\n",
    "b=[i for i in range (150000,200000)]\n",
    "c=[i for i in range (100000,150000)]\n",
    "d=[i for i in range (50000,100000)]\n",
    "e=[i for i in range (0,50000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=np.delete(tx,a,axis=0)\n",
    "x2=np.delete(tx,b,axis=0)\n",
    "x3=np.delete(tx,c,axis=0)\n",
    "x4=np.delete(tx,d,axis=0)\n",
    "x5=np.delete(tx,e,axis=0)\n",
    "y1=np.delete(y,a,axis=0)\n",
    "y2=np.delete(y,b,axis=0)\n",
    "y3=np.delete(y,c,axis=0)\n",
    "y4=np.delete(y,d,axis=0)\n",
    "y5=np.delete(y,e,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.831255\n",
      "0.83283\n",
      "0.83489\n",
      "0.836345\n",
      "0.83785\n",
      "0.83883\n",
      "0.839195\n",
      "0.83941\n",
      "0.83966\n",
      "0.839865\n",
      "0.840065\n",
      "0.839985\n",
      "0.83996\n",
      "0.839925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alperkose/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:4: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.84002\n",
      "2\n",
      "0.83209\n",
      "0.833725\n",
      "0.835805\n",
      "0.837335\n",
      "0.83819\n",
      "0.83903\n",
      "0.83941\n",
      "0.83934\n",
      "0.839585\n",
      "0.83977\n",
      "0.839985\n",
      "0.839875\n",
      "0.839865\n",
      "0.8399\n",
      "0.84001\n",
      "3\n",
      "0.83092\n",
      "0.832745\n",
      "0.83501\n",
      "0.836465\n",
      "0.837715\n",
      "0.83835\n",
      "0.83864\n",
      "0.83901\n",
      "0.83902\n",
      "0.8391\n",
      "0.839245\n",
      "0.83931\n",
      "0.83933\n",
      "0.8394\n",
      "0.839455\n",
      "4\n",
      "0.831585\n",
      "0.833315\n",
      "0.835325\n",
      "0.83676\n",
      "0.838035\n",
      "0.838905\n",
      "0.83914\n",
      "0.83956\n",
      "0.83977\n",
      "0.839845\n",
      "0.84006\n",
      "0.840055\n",
      "0.840145\n",
      "0.84024\n",
      "0.840295\n",
      "5\n",
      "0.83185\n",
      "0.83351\n",
      "0.83554\n",
      "0.83706\n",
      "0.838285\n",
      "0.839295\n",
      "0.839495\n",
      "0.83968\n",
      "0.839745\n",
      "0.83974\n",
      "0.83968\n",
      "0.83971\n",
      "0.839785\n",
      "0.83982\n",
      "0.83986\n"
     ]
    }
   ],
   "source": [
    "#reg_logistic_w=reg_irls(tX,y)\n",
    "print(1)\n",
    "reg_logistic_w1=reg_irls(x1,y1)\n",
    "print(2)\n",
    "reg_logistic_w2=reg_irls(x2,y2)\n",
    "print(3)\n",
    "reg_logistic_w3=reg_irls(x3,y3)\n",
    "print(4)\n",
    "reg_logistic_w4=reg_irls(x4,y4)\n",
    "print(5)\n",
    "reg_logistic_w5=reg_irls(x5,y5)\n",
    "reg_logistic_w=(reg_logistic_w1+reg_logistic_w2+reg_logistic_w3+reg_logistic_w4+reg_logistic_w5)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logistic_w=irls(tX,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '/Users/alperkose/Desktop/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Freeing memory\")\n",
    "del(mat)\n",
    "del(DATA_TRAIN_PATH)\n",
    "del(y)\n",
    "del(tx)\n",
    "del(ids)\n",
    "weights = reg_logistic_w\n",
    "testx = tX_test\n",
    "#testx=np.delete(testx,[14,15,17,18,24,25,27,28],axis=1)\n",
    "testx[testx==-999] = 0\n",
    "#m2=np.mean(testx,axis=0)\n",
    "centered_testx = testx - m\n",
    "centered_testx[testx==-999] = 0\n",
    "#standardized_testx=centered_testx / np.std(centered_testx, axis=0)\n",
    "#centered_testx[centered_testx==0]=float('nan')\n",
    "#stdevtest=np.nanstd(centered_testx,axis=0);\n",
    "#centered_testx[centered_testx==float('nan')]=0\n",
    "standardized_testx = centered_testx / stdevtrain\n",
    "\n",
    "d = len(standardized_testx[0])\n",
    "n = len(standardized_testx)\n",
    "\n",
    "indices_s_deg = []\n",
    "indices_t_deg = []\n",
    "\n",
    "print(\"Creating indices...\")\n",
    "# Creating indices for subsets of degree 2\n",
    "for i in range (d):\n",
    "    for t in range (i,d):\n",
    "        indices_s_deg.append([t, i])\n",
    "indices_s_deg = np.array(indices_s_deg).T\n",
    "\n",
    "# Creating indices for subsets of degree 3\n",
    "max_t_degree = 15\n",
    "for i in range (max_t_degree):\n",
    "    for t in range (i,max_t_degree):\n",
    "        for j in range(t,max_t_degree):\n",
    "            if not (i == t and i == j):\n",
    "                indices_t_deg.append([j, t, i])\n",
    "indices_t_deg = np.array(indices_t_deg).T\n",
    "\n",
    "degrees = range(3,11)\n",
    "degrees_number = len(degrees) + 1\n",
    "stdX_Ncols = standardized_testx.shape[1]\n",
    "indices_s_Ncols = indices_s_deg.shape[1]\n",
    "indices_t_Ncols = indices_t_deg.shape[1]\n",
    "\n",
    "number_of_rows = indices_s_Ncols + degrees_number * stdX_Ncols + indices_t_Ncols\n",
    "\n",
    "mat = np.zeros((n, number_of_rows))\n",
    "\n",
    "print(\"Computing first degree...\")\n",
    "# First degree\n",
    "mat[:, :stdX_Ncols] = standardized_testx\n",
    "\n",
    "print(\"Computing second degree with combinations...\")\n",
    "# Second degree gotten from indices\n",
    "mat[:,stdX_Ncols:stdX_Ncols + indices_s_Ncols] = standardized_testx[:, indices_s_deg[0]] * standardized_testx[:, indices_s_deg[1]]\n",
    "\n",
    "print(\"Computing from degree 3 to 10 without combinations...\")\n",
    "# Improve 3 to 10 degree\n",
    "for i in degrees:\n",
    "    start_index = indices_s_Ncols + (i - 2) * stdX_Ncols\n",
    "    end_index = start_index + stdX_Ncols\n",
    "    mat[:,start_index:end_index] = standardized_testx**i\n",
    "    \n",
    "print(\"Computing third degree with some combinations...\")\n",
    "# Third degree gotten from indices\n",
    "mat[:, number_of_rows - indices_t_Ncols: number_of_rows] = standardized_testx[:, indices_t_deg[0]] * standardized_testx[:, indices_t_deg[1]] * standardized_testx[:, indices_t_deg[2]]  \n",
    "        \n",
    "centered_mat = mat - m2\n",
    "centered_mat[mat==0] = 0\n",
    "\n",
    "print(\"Freeing the matrix memory again\")\n",
    "del(mat)\n",
    "\n",
    "#centered_mat[centered_mat==0]=float('nan')\n",
    "#stdev=np.nanstd(centered_mat,axis=0);\n",
    "#centered_mat[centered_mat==float('nan')]=0\n",
    "standardized_testmat = centered_mat / stdev\n",
    "\n",
    "#tao=int(d*(d+1)/2+d)\n",
    "    \n",
    "#for i in range (n):\n",
    "#    for r in range (d):\n",
    "#        for monsoon in range (r,d):\n",
    "#            for t in range (monsoon,d): \n",
    "#                mat[i,tao]=standardized_tX[i,t]*standardized_tX[i,monsoon]*standardized_tX[i,r]\n",
    "#                tao=tao+1\n",
    "#    tao=int(d*(d+1)/2+d)  \n",
    "    \n",
    "num_samples = len(standardized_testmat)\n",
    "final_testx = np.c_[np.ones(num_samples), standardized_testmat]\n",
    "tX_test = final_testx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '/Users/alperkose/Desktop/deneme8.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = -predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aq=np.dot(testx,reg_logistic_w)  \n",
    "y_guess=np.sign(aq)\n",
    "trueness=sum((y_guess==testy))/len(testy)\n",
    "print(trueness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
